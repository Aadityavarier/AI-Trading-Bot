from __future__ import annotations
import sys
import math
import logging
import warnings
from typing import Dict, Optional, Tuple, Any, List, Union
import json
import numpy as np
import pandas as pd
import numba as nb
from pathlib import Path
import datetime as dt
from dataclasses import dataclass
from scipy import stats
from scipy.optimize import minimize_scalar
import os
from datetime import datetime

try:
    import plotly.graph_objects as go
    from plotly.subplots import make_subplots
    import plotly.express as px
    PLOTLY_AVAILABLE = True
except ImportError:
    PLOTLY_AVAILABLE = False

# ML
from sklearn.pipeline import Pipeline
from sklearn.model_selection import TimeSeriesSplit, ParameterGrid
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.calibration import CalibratedClassifierCV
from sklearn.preprocessing import RobustScaler, QuantileTransformer
from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif, mutual_info_classif
from sklearn.base import BaseEstimator, TransformerMixin, clone

# External models 
try:
    import xgboost as xgb
    XGB_AVAILABLE = True
except ImportError:
    XGB_AVAILABLE = False

try:
    import lightgbm as lgb
    LGB_AVAILABLE = True
except ImportError:
    LGB_AVAILABLE = False

# Data
try:
    import yfinance as yf
    YF_AVAILABLE = True
except ImportError:
    YF_AVAILABLE = False

warnings.filterwarnings("ignore")

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger("AI_Trading_Bot")

# =========================
# Configuration
# =========================
@dataclass
class TradingConfig:
    # Risk parameters
    target_annual_vol: float = 0.18
    max_drawdown: float = 0.12
    max_position_pct: float = 0.40
    min_confidence: float = 0.58
    
    # Stop loss / Take profit
    stop_atr_multiplier: float = 3.0
    tp_atr_multiplier: float = 5.0
    trailing_atr_multiplier: float = 1.5
    max_hold_days: int = 35
    
    # Position sizing
    kelly_fraction: float = 0.6  
    vol_lookback: int = 60
    
    # Cost parameters 
    brokerage_bps: float = 5.0
    stt_bps: float = 10.0
    impact_coefficient: float = 0.1

# =========================
# Fast utilities 
# =========================
@nb.njit(cache=True)
def fast_rolling_mean(a: np.ndarray, w: int) -> np.ndarray:
    out = np.empty_like(a)
    out[:] = np.nan
    csum = 0.0
    for i in range(a.size):
        csum += a[i]
        if i >= w:
            csum -= a[i - w]
        if i >= w - 1:
            out[i] = csum / w
    return out

@nb.njit(cache=True)
def fast_rolling_std(a: np.ndarray, w: int) -> np.ndarray:
    out = np.empty_like(a)
    out[:] = np.nan
    for i in range(a.size):
        if i >= w - 1:
            window = a[i - w + 1:i + 1]
            m = 0.0
            for v in window:
                m += v
            m /= w
            s = 0.0
            for v in window:
                d = v - m
                s += d * d
            out[i] = math.sqrt(s / w)
    return out

@nb.njit(cache=True)
def fast_rsi(prices: np.ndarray, period: int = 14) -> np.ndarray:
    rsi = np.empty_like(prices)
    rsi[:] = np.nan
    deltas = np.diff(prices)
    if deltas.size < period + 1:
        return rsi
    
    seed = deltas[:period]
    up = 0.0
    down = 0.0
    for d in seed:
        if d > 0:
            up += d
        else:
            down -= d
    up /= period
    down /= period if down != 0 else 1.0
    rs = up / down if down != 0 else 0.0
    rsi[period] = 100. - 100. / (1. + rs)
    
    for i in range(period + 1, prices.size):
        delta = deltas[i - 1]
        upval = delta if delta > 0 else 0.0
        downval = -delta if delta < 0 else 0.0
        up = (up * (period - 1) + upval) / period
        down = (down * (period - 1) + downval) / period if down != 0 else 1.0
        rs = up / down if down != 0 else 0.0
        rsi[i] = 100. - 100. / (1. + rs)
    return rsi

@nb.njit(cache=True)
def fast_bb_position(prices: np.ndarray, period: int = 20, std_mult: float = 2.0) -> np.ndarray:
    sma = fast_rolling_mean(prices, period)
    std = fast_rolling_std(prices, period)
    bb_pos = np.empty_like(prices)
    bb_pos[:] = np.nan
    
    for i in range(len(prices)):
        if not np.isnan(sma[i]) and not np.isnan(std[i]) and std[i] > 0:
            bb_pos[i] = (prices[i] - sma[i]) / (std_mult * std[i])
        else:
            bb_pos[i] = 0.0
    return bb_pos

# =========================
# Performance metrics
# =========================
def cagr(returns: pd.Series) -> float:
    """Compound Annual Growth Rate"""
    if len(returns) < 2:
        return 0.0
    cumulative = (1 + returns).cumprod()
    years = len(returns) / 252.0  # Trading days
    if years <= 0:
        return 0.0
    end_val = cumulative.iloc[-1]
    return (end_val ** (1 / years)) - 1 if end_val > 0 else -1.0

def sharpe_ratio(returns: pd.Series, rf: float = 0.06) -> float:
    """Sharpe ratio with risk-free rate"""
    if returns.std() == 0 or len(returns) == 0:
        return 0.0
    excess = returns - rf / 252
    return excess.mean() / returns.std() * np.sqrt(252)

def sortino_ratio(returns: pd.Series, rf: float = 0.06) -> float:
    """Sortino ratio focusing on downside deviation"""
    excess = returns - rf / 252
    downside = excess[excess < 0]
    if len(downside) == 0 or downside.std() == 0:
        return 0.0
    return excess.mean() / downside.std() * np.sqrt(252)

def max_drawdown(cum_returns: pd.Series) -> float:
    """Maximum drawdown from peak"""
    peak = cum_returns.cummax()
    dd = (cum_returns - peak) / peak
    return dd.min()

def calmar_ratio(returns: pd.Series) -> float:
    """Calmar ratio = CAGR / |Max Drawdown|"""
    cum = (1 + returns).cumprod()
    md = abs(max_drawdown(cum))
    cg = cagr(returns)
    return cg / md if md > 0 else 0.0

def omega_ratio(returns: pd.Series, threshold: float = 0.0) -> float:
    """Omega ratio - probability weighted ratio of gains vs losses"""
    excess = returns - threshold / 252
    gains = excess[excess > 0].sum()
    losses = -excess[excess < 0].sum()
    return gains / losses if losses > 0 else float('inf')

def safe_divide(numerator: pd.Series, denominator: pd.Series, default_val: float = 1.0) -> pd.Series:
        """Safely divide two series, handling zeros and infinities"""
        # Replace zero denominators with a small epsilon
        denominator = denominator.replace(0, 1e-8)
        
        # Perform division
        result = numerator / denominator
        
        # Replace infinities and extreme values
        result = result.replace([np.inf, -np.inf], default_val)
        
        # Cap extreme values
        result = result.clip(-1000, 1000)  
        
        return result.fillna(default_val)
    
# =========================
# Regime detection
# =========================
class RegimeDetector:
    """Multi-dimensional regime detection using volatility, trend, and momentum"""
    
    def __init__(self):
        self.vol_periods = [10, 20, 60]
        self.trend_periods = [5, 20, 50]
        self.mom_periods = [5, 10, 20]
    
    def detect_volatility_regime(self, returns: pd.Series) -> pd.Series:
        """Detect high/low volatility regimes"""
        vol_short = returns.rolling(10).std()
        vol_long = returns.rolling(60).std()
        vol_ratio = vol_short / vol_long
        
        # Regime classification: 0=normal, 1=high vol, -1=low vol
        regime = pd.Series(0, index=returns.index)
        regime[vol_ratio > 1.5] = 1  
        regime[vol_ratio < 0.7] = -1  
        
        return regime.fillna(0)
    
    def detect_trend_regime(self, prices: pd.Series) -> pd.Series:
        """Detect trend regimes using multiple SMAs"""
        sma5 = prices.rolling(5).mean()
        sma20 = prices.rolling(20).mean()
        sma50 = prices.rolling(50).mean()
        
        # Trend strength
        trend_strength = (sma5 - sma50) / sma50
        
        # Regime classification
        regime = pd.Series(0, index=prices.index)
        regime[trend_strength > 0.02] = 1   # Uptrend
        regime[trend_strength < -0.02] = -1  # Downtrend
        
        return regime.fillna(0)
    
    def detect_momentum_regime(self, prices: pd.Series) -> pd.Series:
        """Detect momentum regimes"""
        mom5 = prices.pct_change(5)
        mom20 = prices.pct_change(20)
        
        # Momentum score
        mom_score = (mom5 + mom20 * 0.5) / 1.5
        mom_vol = mom_score.rolling(20).std()
        
        regime = pd.Series(0, index=prices.index)
        regime[mom_score > mom_vol] = 1    
        regime[mom_score < -mom_vol] = -1   
        
        return regime.fillna(0)
    
    def detect_market_stress(self, df: pd.DataFrame) -> pd.Series:
        """Detect market stress using price gaps and volume"""
        close = df['close']
        open_price = df['open']
        volume = df['volume']
        
        # Price gaps
        gaps = ((open_price - close.shift(1)) / close.shift(1)).abs()
        
        # Volume spikes
        vol_ma = volume.rolling(20).mean()
        vol_spike = volume / vol_ma
        
        # Stress indicator
        stress = (gaps > 0.03) | (vol_spike > 2.0)
        return stress.astype(int)
    
    def detect(self, df: pd.DataFrame) -> pd.DataFrame:
        """Main regime detection method"""
        close = df['close']
        returns = close.pct_change().fillna(0)
        
        regimes = pd.DataFrame({
            'vol_regime': self.detect_volatility_regime(returns),
            'trend_regime': self.detect_trend_regime(close),
            'mom_regime': self.detect_momentum_regime(close),
            'stress_regime': self.detect_market_stress(df)
        }, index=df.index)
        
        # Overall regime score
        regimes['regime_score'] = (
            regimes['trend_regime'] * 0.4 +
            regimes['mom_regime'] * 0.3 +
            regimes['vol_regime'] * 0.2 -
            regimes['stress_regime'] * 0.1
        )
        
        return regimes.fillna(0)
    
    def allow_trade(self, regime_row: pd.Series) -> bool:
        """Determine if trading is allowed based on regime"""
        if regime_row.get('stress_regime', 0) == 1:
            return False
        
        if regime_row.get('regime_score', 0) < -1.5:
            return False
            
        if (regime_row.get('vol_regime', 0) == 1 and 
            regime_row.get('trend_regime', 0) == -1):
            return False
            
        return True

# =========================
# Feature engineering
# =========================
class FeatureBuilder:
    """Feature engineering with multi-timeframe analysis"""
    
    def __init__(self):
        self.regime_detector = RegimeDetector()
    
    def technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """Technical Indicators with multi-timeframe analysis"""
        close = df['close']
        high = df['high']
        low = df['low']
        volume = df['volume']
        
        features = pd.DataFrame(index=df.index)
        
        # Williams %R
        for period in [14, 21, 28]:
            highest_high = high.rolling(period).max()
            lowest_low = low.rolling(period).min()
            features[f'williams_r_{period}'] = (highest_high - close) / (highest_high - lowest_low + 1e-8) * -100

        # PRICE MOMENTUM FEATURES
        for period in [3, 5, 8, 13, 21]:  # Fibonacci periods
            momentum = close.pct_change(period)
            features[f'momentum_{period}d'] = momentum
            
            # Momentum consistency (trending vs choppy)
            mom_std = momentum.rolling(10).std()
            features[f'momentum_consistency_{period}d'] = abs(momentum) / (mom_std + 1e-8)
        
         # Stochastic Oscillator
        for period in [14, 21]:
            lowest_low = low.rolling(period).min()
            highest_high = high.rolling(period).max()
            k_percent = 100 * (close - lowest_low) / (highest_high - lowest_low + 1e-8)
            features[f'stoch_k_{period}'] = k_percent
            features[f'stoch_d_{period}'] = k_percent.rolling(3).mean()
        
        # MACD
            ema12 = close.ewm(span=12).mean()
            ema26 = close.ewm(span=26).mean()
            macd = ema12 - ema26
            signal = macd.ewm(span=9).mean()
            features['macd'] = macd
            features['macd_signal'] = signal
            features['macd_histogram'] = macd - signal
        
        # Bollinger Bands
        for period in [20, 50]:
            sma = close.rolling(period).mean()
            std = close.rolling(period).std()
            features[f'bb_upper_{period}'] = sma + (2 * std)
            features[f'bb_lower_{period}'] = sma - (2 * std)
            features[f'bb_position_{period}'] = (close - sma) / (2 * std)
            features[f'bb_width_{period}'] = (2 * std) / sma
        
        # Average True Range
            tr1 = high - low
            tr2 = abs(high - close.shift(1))
            tr3 = abs(low - close.shift(1))
            true_range = pd.DataFrame({'tr1': tr1, 'tr2': tr2, 'tr3': tr3}).max(axis=1)
            features['atr_14'] = true_range.rolling(14).mean()
            features['atr_21'] = true_range.rolling(21).mean()
    
        # VOLATILITY REGIME FEATURES
        returns = close.pct_change().fillna(0)
        for period in [5, 10, 20]:
            vol = returns.rolling(period).std()
            features[f'volatility_{period}d'] = vol
            
            # Volatility percentile (adaptive)
            features[f'vol_percentile_{period}d'] = vol.rolling(60).rank(pct=True)
        
        # PRICE POSITION FEATURES
        for period in [10, 20, 50]:
            high_period = high.rolling(period).max()
            low_period = low.rolling(period).min()
            
            # % position within recent range
            range_size = high_period - low_period + 1e-8
            features[f'price_position_{period}d'] = (close - low_period) / range_size
            
            # Distance from highs/lows
            features[f'distance_from_high_{period}d'] = (high_period - close) / close
            features[f'distance_from_low_{period}d'] = (close - low_period) / close
        
        # RSI WITH MULTIPLE PERIODS
        for period in [7, 14, 21]:
            rsi = pd.Series(fast_rsi(close.values, period), index=close.index)
            features[f'rsi_{period}'] = rsi
            
            # RSI momentum (rate of change)
            features[f'rsi_momentum_{period}'] = rsi.pct_change(5)
            
            # RSI divergence proxy
            price_momentum = close.pct_change(period)
            rsi_momentum = rsi.pct_change(period)
            features[f'rsi_divergence_{period}'] = (np.sign(price_momentum) != np.sign(rsi_momentum)).astype(int)
        
            # VOLUME-PRICE ANALYSIS
            vwap = (volume * close).rolling(20).sum() / volume.rolling(20).sum()
            features['vwap_deviation'] = (close - vwap) / vwap
            
            # Volume rate of change
            volume_roc = volume.pct_change(5)
            features['volume_momentum'] = volume_roc
            
            # Price-volume relationship
            price_roc = close.pct_change(5)
            features['price_volume_correlation'] = price_roc.rolling(20).corr(volume_roc)
            
        return features.fillna(0)


    def market_microstructure_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """Market microstructure signals"""
        features = pd.DataFrame(index=df.index)
        
        open_price = df['open']
        close = df['close']
        high = df['high']
        low = df['low']
        volume = df['volume']
        
        # INTRADAY PATTERNS
        intraday_return = (close - open_price) / open_price
        overnight_return = (open_price - close.shift(1)) / close.shift(1)
        
        features['intraday_return'] = intraday_return
        features['overnight_return'] = overnight_return
        
        # Return decomposition significance
        total_return = close.pct_change()
        intraday_weight = abs(intraday_return) / (abs(intraday_return) + abs(overnight_return) + 1e-8)
        features['intraday_weight'] = intraday_weight
        
        # GAP ANALYSIS 
        gap_size = (open_price - close.shift(1)) / close.shift(1)
        features['gap_size'] = gap_size
        
        # Gap follow-through 
        gap_up_mask = gap_size > 0.005
        gap_down_mask = gap_size < -0.005
        
        gap_fill_up = gap_up_mask & (low <= close.shift(1))
        gap_fill_down = gap_down_mask & (high >= close.shift(1))
        
        features['gap_fill_probability'] = (gap_fill_up | gap_fill_down).rolling(20).mean()
        
        # VOLUME ANALYSIS
        volume_ma = volume.rolling(20).mean()
        features['volume_ratio'] = volume / (volume_ma + 1e-8)
        
        # Volume-weighted returns
        volume_weight = volume / volume.rolling(20).sum()
        features['volume_weighted_return'] = (total_return * volume_weight).rolling(20).sum()
        
        # REVERSAL PATTERNS
        # Hammer/Doji detection 
        body_size = abs(close - open_price)
        total_range = high - low + 1e-8
        upper_shadow = high - np.maximum(close, open_price)
        lower_shadow = np.minimum(close, open_price) - low
        
        features['body_ratio'] = body_size / total_range
        features['upper_shadow_ratio'] = upper_shadow / total_range
        features['lower_shadow_ratio'] = lower_shadow / total_range
        
        # Hammer pattern (small body, long lower shadow)
        features['hammer_signal'] = (
            (features['body_ratio'] < 0.3) & 
            (features['lower_shadow_ratio'] > 0.6) &
            (close.pct_change() < -0.01)  
        ).astype(int)
        
        return features.fillna(0)

    
    def cross_asset_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """Features that might correlate with broader market"""
        features = pd.DataFrame(index=df.index)
        
        close = df['close']
        returns = close.pct_change()
        
        # Volatility clustering
        features['vol_cluster'] = (returns.abs() > returns.rolling(20).std() * 1.5).astype(int)
        
        # Serial correlation
        features['serial_corr'] = returns.rolling(10).apply(
            lambda x: x.autocorr(lag=1) if len(x) > 1 else 0
        ).fillna(0)
        
        # Trend persistence
        trend_5 = (close > close.rolling(5).mean()).astype(int)
        features['trend_persistence'] = trend_5.rolling(5).mean()
        
        return features.fillna(0)
    
    def market_correlation_features(self, df: pd.DataFrame, market_data: pd.DataFrame = None) -> pd.DataFrame:
        """Add market correlation and sector features"""
        features = pd.DataFrame(index=df.index)
        close = df['close']
        returns = close.pct_change()
    
        
        # Download Nifty 50 for market correlation if not provided
        if market_data is None:
            try:
                import yfinance as yf
                nifty = yf.download("^NSEI", period="2y")['Close']
                nifty_returns = nifty.pct_change()
            except:
                nifty_returns = returns 
        else:
            nifty_returns = market_data['close'].pct_change()
        
        # Rolling correlation with market
        features['market_corr_30d'] = returns.rolling(30).corr(nifty_returns)
        features['market_corr_60d'] = returns.rolling(60).corr(nifty_returns)
        
        # Beta calculation
        covariance = returns.rolling(60).cov(nifty_returns)
        market_variance = nifty_returns.rolling(60).var()
        features['beta_60d'] = safe_divide(covariance, market_variance)
        
        # Relative strength vs market
        if market_data is not None:
            stock_perf = (close / close.rolling(20).mean() - 1)
            market_perf = (market_data['close'] / market_data['close'].rolling(20).mean() - 1)
            features['relative_strength'] = stock_perf - market_perf
        else:
            features['relative_strength'] = 0
        
        # Market regime alignment
        features['market_trend_align'] = (
            (returns > 0).astype(int) * (nifty_returns > 0).astype(int)
        )
        
        return features.fillna(0)

    def build_features(self, df: pd.DataFrame, horizon: int = 1, market_data: pd.DataFrame = None) -> pd.DataFrame:
        """Feature building with validation"""
        
        signal_validator = SignalValidator()
        
        tech_features = self.technical_indicators(df)
        micro_features = self.market_microstructure_features(df)
        cross_features = self.cross_asset_features(df)
        time_features = self.time_based_features(df)
        
        if market_data is not None:
            market_corr_features = self.market_correlation_features(df, market_data)
            all_features = pd.concat([tech_features, micro_features, cross_features, 
                                    time_features, market_corr_features], axis=1)
        else:
            market_corr_features = self.market_correlation_features(df, None)
            all_features = pd.concat([tech_features, micro_features, cross_features,
                                    time_features, market_corr_features], axis=1)
        
        regime_features = self.regime_detector.detect(df)
        all_features = pd.concat([all_features, regime_features], axis=1)
        
        close = df['close']
        open_next = df['open'].shift(-horizon)
        close_next = df['close'].shift(-horizon)
        forward_return = (close_next - open_next) / open_next
        
        logger.info(" Starting individual feature validation...")
        validated_features = pd.DataFrame(index=df.index)
        
        for feature_name in all_features.columns:
            if signal_validator.test_feature_predictive_power(
                all_features[feature_name], forward_return, feature_name, min_ic=0.01
            ):
                validated_features[feature_name] = all_features[feature_name]
        
        if len(validated_features.columns) == 0:
            logger.warning(" No features passed validation, using top 20 by correlation")
            correlations = all_features.corrwith(forward_return).abs().sort_values(ascending=False)
            top_features = correlations.head(20).index
            validated_features = all_features[top_features]
        else:
            logger.info(f" {len(validated_features.columns)} features passed validation")
        
        validated_features['target_return'] = forward_return
        validated_features['target_direction'] = (forward_return > 0).astype(int)
        
        return self._clean_features(validated_features)



    def _clean_features(self, features: pd.DataFrame) -> pd.DataFrame:
        """Clean features to remove infinities and extreme values"""
        logger.info("Cleaning features for ML compatibility...")
        
        for col in features.columns:
            features[col] = pd.to_numeric(features[col], errors='coerce')
        
        features = features.replace([np.inf, -np.inf], np.nan)
        
        for col in features.columns:
            if col in ['target_return', 'target_direction']:
                continue
                
            if features[col].isna().any():
                median_val = features[col].median()
                if pd.isna(median_val):  
                    median_val = 0.0
                features[col] = features[col].fillna(median_val)
        
        for col in features.columns:
            if col in ['target_return', 'target_direction']:
                continue
                
            upper_cap = features[col].quantile(0.995)
            lower_cap = features[col].quantile(0.005)
            
            if not pd.isna(upper_cap) and not pd.isna(lower_cap):
                features[col] = features[col].clip(lower=lower_cap, upper=upper_cap)
        
        features = features.select_dtypes(include=[np.number])  
        
        features = features.dropna(subset=['target_return', 'target_direction'])
        
        logger.info(f"Feature cleaning complete. Shape: {features.shape}")
        return features
    
    def time_based_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """Add time-based cyclical features"""
        features = pd.DataFrame(index=df.index)
        
        # Day of week effects 
        features['day_of_week'] = df.index.dayofweek
        features['is_monday'] = (df.index.dayofweek == 0).astype(int)
        features['is_friday'] = (df.index.dayofweek == 4).astype(int)
        
        # Month effects
        features['month'] = df.index.month
        features['is_march'] = (df.index.month == 3).astype(int)  # Financial year end
        features['is_october'] = (df.index.month == 10).astype(int)  # Festive season
        
        features['day_sin'] = np.sin(2 * np.pi * df.index.dayofweek / 7)
        features['day_cos'] = np.cos(2 * np.pi * df.index.dayofweek / 7)
        features['month_sin'] = np.sin(2 * np.pi * df.index.month / 12)
        features['month_cos'] = np.cos(2 * np.pi * df.index.month / 12)
        
        return features
    
    def create_multi_horizon_targets(self, df: pd.DataFrame) -> pd.DataFrame:
        """Create targets for multiple prediction horizons"""
        close = df['close']
        open_price = df['open']
        
        targets = pd.DataFrame(index=df.index)
        
        # 1-day target 
        open_next1 = open_price.shift(-1)
        close_next1 = close.shift(-1)
        ret_1d = (close_next1 - open_next1) / open_next1
        targets['target_return_1d'] = ret_1d
        
        # 2-day target
        open_next2 = open_price.shift(-2)
        close_next2 = close.shift(-2)
        ret_2d = (close_next2 - open_next1) / open_next1
        targets['target_return_2d'] = ret_2d
        
        # 3-day target
        open_next3 = open_price.shift(-3)
        close_next3 = close.shift(-3)
        ret_3d = (close_next3 - open_next1) / open_next1
        targets['target_return_3d'] = ret_3d
        
        # Ensemble target: weighted combination
        targets['target_return_ensemble'] = (
            ret_1d * 0.5 + ret_2d * 0.3 + ret_3d * 0.2
        )
        
        # Direction targets
        targets['target_direction_1d'] = (ret_1d > 0).astype(int)
        targets['target_direction_2d'] = (ret_2d > 0).astype(int) 
        targets['target_direction_3d'] = (ret_3d > 0).astype(int)
        targets['target_direction_ensemble'] = (targets['target_return_ensemble'] > 0).astype(int)
        
        return targets

    def add_multi_timeframe_confirmation(self, df: pd.DataFrame) -> pd.DataFrame:
        """Add multi-timeframe trend confirmation"""
        close = df['close']
        features = pd.DataFrame(index=df.index)
        
        sma_5 = close.rolling(5).mean()
        sma_20 = close.rolling(20).mean()
        sma_50 = close.rolling(50).mean()
        
        bullish_alignment = (close > sma_5) & (sma_5 > sma_20) & (sma_20 > sma_50)
        bearish_alignment = (close < sma_5) & (sma_5 < sma_20) & (sma_20 < sma_50)
        
        features['trend_alignment'] = bullish_alignment.astype(int) - bearish_alignment.astype(int)
        return features

class SignalValidator:
    """Test individual features for predictive power before using them"""
    
    def __init__(self):
        self.feature_scores = {}
        self.validated_features = []
    
    def test_feature_predictive_power(self, feature_series: pd.Series, targets: pd.Series, 
                                    feature_name: str, min_ic: float = 0.02) -> bool:
        """Test if a feature has predictive power using Information Coefficient"""
        try:
            from scipy.stats import spearmanr
            
            valid_idx = ~(feature_series.isna() | targets.isna())
            if valid_idx.sum() < 50:
                return False
            
            clean_feature = feature_series[valid_idx]
            clean_targets = targets[valid_idx]
            
            ic, p_value = spearmanr(clean_feature, clean_targets)
            
            is_valid = abs(ic) > min_ic and p_value < 0.1
            
            self.feature_scores[feature_name] = {
                'information_coefficient': ic,
                'p_value': p_value,
                'is_valid': is_valid
            }
            
            if is_valid:
                self.validated_features.append(feature_name)
                logger.info(f" Feature '{feature_name}' validated: IC={ic:.4f}, p={p_value:.4f}")
            
            return is_valid
            
        except Exception as e:
            logger.warning(f"Error validating feature {feature_name}: {e}")
            return False
        
# =========================
# ML Pipeline
# =========================
class MLPipeline:
    """ ML pipeline with ensemble methods """
    
    def __init__(self, config: TradingConfig):
        self.config = config
        self.pipeline: Optional[Pipeline] = None
        self.feature_importance_: Optional[pd.Series] = None
        self.calibration_curve_: Optional[Dict] = None
        
    def create_ensemble(self) -> VotingClassifier:
        """Create ensemble focused on SIGNAL QUALITY"""
        models = []
        
        rf = RandomForestClassifier(
            n_estimators=500,  
            max_depth=8,       
            min_samples_split=20,  
            min_samples_leaf=10,    
            max_features='sqrt',   
            class_weight='balanced_subsample',  
            bootstrap=True,
            random_state=42
        )
        models.append(('rf', rf))
        
        
        from sklearn.ensemble import ExtraTreesClassifier
        et = ExtraTreesClassifier(
            n_estimators=500,
            max_depth=10,
            min_samples_split=20,
            min_samples_leaf=10,
            max_features='sqrt',
            class_weight='balanced_subsample',
            random_state=42
        )
        models.append(('et', et))
        
        # XGBoost 
        if XGB_AVAILABLE:
            xgb_model = xgb.XGBClassifier(
                n_estimators=500,
                learning_rate=0.01,  
                max_depth=6,
                subsample=0.8,
                colsample_bytree=0.8,
                reg_alpha=0.3,     
                reg_lambda=0.5,     
                scale_pos_weight=1.0,
                random_state=42,
                eval_metric='logloss'
            )
            models.append(('xgb', xgb_model))
        
        return VotingClassifier(estimators=models, voting='soft')

    
    def create_pipeline(self) -> Pipeline:
        """Create full ML pipeline"""
        steps = [
            ('variance_threshold', VarianceThreshold(threshold=1e-6)),
            ('feature_selection', SelectKBest(
                score_func=mutual_info_classif, 
                k=min(30, int(self.n_features_ * 0.6))  
            )),
            ('scaler', QuantileTransformer(
                output_distribution='uniform',
                n_quantiles=1000,
                subsample=100000
            )),
            ('classifier', self.create_ensemble())
        ]
        
        return Pipeline(steps)
    
    def fit(self, X: pd.DataFrame, y: pd.Series, n_splits: int = 5) -> Dict[str, float]:
        """Fit pipeline with time series cross-validation"""
        self.n_features_ = X.shape[1]
        self.X_train = X.copy()  
        base_pipeline = self.create_pipeline()
        
        tscv = TimeSeriesSplit(n_splits=n_splits)
        
        calibrated_clf = CalibratedClassifierCV(
            estimator=base_pipeline,
            method='isotonic',
            cv=tscv
        )
        
        logger.info("Fitting calibrated ensemble model...")
        calibrated_clf.fit(X, y)
        self.pipeline = calibrated_clf
        
        last_metrics = self._evaluate_last_fold(X, y, tscv)
        
        try:
            self._extract_feature_importance()
        except Exception as e:
            logger.warning(f"Could not extract feature importance: {e}")
        
        return last_metrics

    
    def _evaluate_last_fold(self, X: pd.DataFrame, y: pd.Series, tscv) -> Dict[str, float]:
        """Evaluate performance on the last fold"""
        splits = list(tscv.split(X))
        if not splits:
            return {}
        
        train_idx, test_idx = splits[-1]
        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
        
        temp_pipeline = self.create_pipeline()
        temp_pipeline.fit(X_train, y_train)
        
        # Predictions
        y_prob = temp_pipeline.predict_proba(X_test)[:, 1]
        y_pred = (y_prob > 0.5).astype(int)
        
        metrics = {
            'accuracy': accuracy_score(y_test, y_pred),
            'precision': precision_score(y_test, y_pred, zero_division=0),
            'recall': recall_score(y_test, y_pred, zero_division=0),
            'f1': f1_score(y_test, y_pred, zero_division=0),
            'auc': roc_auc_score(y_test, y_prob)
        }
        
        logger.info(f"Last fold validation metrics: {metrics}")
        return metrics
    
    def _extract_feature_importance(self):
        """Extract feature importance from the ensemble"""
        try:
            if hasattr(self.pipeline, 'calibrated_classifiers_'):
                base_pipeline = self.pipeline.calibrated_classifiers_[0]
                
                if hasattr(base_pipeline, 'named_steps'):
                    classifier = base_pipeline.named_steps['classifier']
                    
                    if hasattr(classifier, 'estimators_'):
                        importances_list = []
                        for name, estimator in classifier.estimators_:
                            if hasattr(estimator, 'feature_importances_'):
                                importances_list.append(estimator.feature_importances_)
                        
                        if importances_list:
                            avg_importance = np.mean(importances_list, axis=0)
                            
                            feature_selector = base_pipeline.named_steps['feature_selection']
                            selected_features = feature_selector.get_support(indices=True)
                            original_features = list(self.X_train.columns)
                            selected_feature_names = [original_features[i] for i in selected_features]
                            
                            self.feature_importance_ = pd.Series(avg_importance, index=selected_feature_names)
                            logger.info(" Feature importance extraction successful")
                            return
            
            logger.info(" VotingClassifier doesn't expose unified feature importance (this is normal)")
            
        except Exception as e:
            logger.info(f" Feature importance extraction skipped: {e} (this is normal for ensemble methods)")



    
    def predict_proba(self, X: pd.DataFrame) -> np.ndarray:
        """Get prediction probabilities"""
        if self.pipeline is None:
            raise RuntimeError("Model not fitted")
        return self.pipeline.predict_proba(X)[:, 1]
    
    def get_feature_importance(self) -> Optional[pd.Series]:
        """Get feature importance if available"""
        return self.feature_importance_
    def create_ensemble(self) -> VotingClassifier:
        """Create ensemble with diverse models"""
        models = []
        
        # Gradient Boosting
        gb = GradientBoostingClassifier(
            n_estimators=300,
            learning_rate=0.03,
            max_depth=4,
            subsample=0.7,
            max_features='sqrt',
            random_state=42
        )
        models.append(('gb', gb))
        
        # Random Forest
        rf = RandomForestClassifier(
            n_estimators=300,
            max_depth=8,
            min_samples_leaf=3,
            max_features=0.6,
            class_weight='balanced_subsample',
            random_state=42
        )
        models.append(('rf', rf))
        
        # XGBoost 
        if XGB_AVAILABLE:
            xgb_model = xgb.XGBClassifier(
                n_estimators=300,
                learning_rate=0.03,
                max_depth=4,
                subsample=0.7,
                colsample_bytree=0.7,
                reg_alpha=0.2,
                reg_lambda=1.5,
                scale_pos_weight=1.2,  
                random_state=42,
                eval_metric='logloss'
            )
            models.append(('xgb', xgb_model))
        
        return VotingClassifier(estimators=models, voting='soft')
   
# =========================
# Dynamic threshold optimization
# =========================
class DynamicThresholdOptimizer:
    """Optimize thresholds dynamically based on market regimes and model confidence"""
    
    def __init__(self, config: TradingConfig):
        self.config = config
        self.regime_thresholds: Dict[str, float] = {
            'default': 0.60,      
            'high_vol': 0.65,    
            'low_vol': 0.58,   
            'uptrend': 0.58,      
            'downtrend': 0.62     
        }
        
    def optimize_by_regime(self, 
                          probabilities: pd.Series,
                          targets: pd.Series, 
                          regimes: pd.DataFrame,
                          returns: pd.Series) -> Dict[str, float]:
        """Optimize thresholds for each market regime"""
        
        regime_thresholds = {}
        
        regime_codes = regimes.apply(lambda row: self._create_regime_code(row), axis=1)
        unique_regimes = regime_codes.unique()
        
        for regime in unique_regimes:
            mask = regime_codes == regime
            if mask.sum() < 50: 
                continue
                
            regime_probs = probabilities[mask]
            regime_targets = targets[mask] 
            regime_returns = returns[mask]
            
            
            best_threshold = self._optimize_single_regime(
                regime_probs, regime_targets, regime_returns
            )
            
            regime_thresholds[regime] = best_threshold
            
        regime_thresholds['default'] = self.config.min_confidence
        
        logger.info(f"Optimized thresholds by regime: {regime_thresholds}")
        return regime_thresholds
    
    def _create_regime_code(self, regime_row: pd.Series) -> str:
        """Create regime code from regime features"""
        vol_regime = int(regime_row.get('vol_regime', 0))
        trend_regime = int(regime_row.get('trend_regime', 0))
        stress = int(regime_row.get('stress_regime', 0))
        return f"V{vol_regime}_T{trend_regime}_S{stress}"
    
    def _optimize_single_regime(self, 
                               probabilities: pd.Series,
                               targets: pd.Series,
                               returns: pd.Series) -> float:
        """Optimize threshold for single regime using Kelly criterion"""
        
        thresholds = np.arange(0.50, 0.80, 0.02)
        best_threshold = 0.55
        best_score = -np.inf
        
        for threshold in thresholds:
            predictions = (probabilities > threshold).astype(int)
            
            if predictions.sum() == 0:  # No trades
                continue
                
            # Calculate win rate and average win/loss
            trade_returns = returns[predictions == 1]
            
            if len(trade_returns) < 5:
                continue
                
            win_rate = (trade_returns > 0).mean()
            avg_win = trade_returns[trade_returns > 0].mean() if (trade_returns > 0).any() else 0
            avg_loss = abs(trade_returns[trade_returns < 0].mean()) if (trade_returns < 0).any() else 0.01
            
            # Kelly criterion score
            if avg_loss > 0:
                win_loss_ratio = avg_win / avg_loss
                kelly_score = win_rate - (1 - win_rate) / win_loss_ratio
                
                
                frequency_penalty = min(1.0, len(trade_returns) / 20)
                score = kelly_score * frequency_penalty
                
                if score > best_score:
                    best_score = score
                    best_threshold = threshold
        
        return best_threshold
    
    def get_threshold(self, regime_row: pd.Series) -> float:
        """Get threshold for current regime"""
        regime_code = self._create_regime_code(regime_row)
        return self.regime_thresholds.get(regime_code, self.config.min_confidence)

# =========================
# Position sizing
# =========================
class KellyPositionSizer:
    """Kelly criterion-based position sizing with risk controls"""
    
    def __init__(self, config: TradingConfig):
        self.config = config
        
    def calculate_size(self, 
                      capital: float,
                      price: float, 
                      probability: float,
                      expected_return: float,
                      volatility: float,
                      max_position_value: float) -> float:
        """Calculate position size using modified Kelly criterion"""
        
        win_rate = probability
        
        vol_adjustment = 1.0
        if volatility < 0.015:      
            vol_adjustment = 1.3    
        elif volatility > 0.035:    
            vol_adjustment = 0.7    

        # Conservative estimates
        avg_win = max(0.02, expected_return * 1.5)  
        avg_loss = max(0.015, volatility * 1.2)     
        
        win_loss_ratio = avg_win / avg_loss
        
        # Kelly fraction
        kelly_f = win_rate - (1 - win_rate) / win_loss_ratio
        kelly_f *= vol_adjustment

        # Safety factors
        kelly_f = max(0, min(kelly_f, 0.25))  
        kelly_f *= self.config.kelly_fraction   
        
        # Volatility adjustment
        target_vol = self.config.target_annual_vol / np.sqrt(252)  
        vol_adjustment = target_vol / max(volatility, 0.01)
        vol_adjustment = min(vol_adjustment, 2.0)   
        
        # Final position value
        position_value = capital * kelly_f * vol_adjustment
        position_value = min(position_value, max_position_value)
        
        # Convert to shares
        shares = position_value / price
        
        return max(0, shares)

# =========================
# Risk management
# =========================
class RiskManager:
    """Comprehensive risk management system"""
    
    def __init__(self, config: TradingConfig):
        self.config = config
        self.position_sizer = KellyPositionSizer(config)
        self.drawdown_history: List[float] = []
        
    def calculate_position_size(self,
                               capital: float,
                               price: float,
                               probability: float, 
                               volatility: float,
                               atr: float) -> float:
        """Calculate position size with multiple constraints"""
        
        # Maximum position value based on capital
        max_position_value = capital * self.config.max_position_pct
        
        # Expected return estimate 
        expected_return = (probability - 0.5) * 0.04  
        
        # Kelly-based sizing
        kelly_size = self.position_sizer.calculate_size(
            capital, price, probability, expected_return, volatility, max_position_value
        )
        
        # Volatility-based sizing 
        vol_target = self.config.target_annual_vol / np.sqrt(252)
        vol_size = (vol_target * capital) / (volatility * price) if volatility > 0 else 0
        
        
        final_size = min(kelly_size, vol_size)
        
       
        final_size = min(final_size, max_position_value / price)
        
        return max(0, math.floor(final_size))
    
    def should_enter_position(self,
                             probability: float,
                             regime_row: pd.Series,
                             current_drawdown: float) -> bool:
        """Determine if position entry is allowed"""
        
        # Check minimum confidence
        if probability < self.config.min_confidence:
            return False
            
        # Check drawdown limit
        if current_drawdown < -self.config.max_drawdown:
            return False
            
        # Volatility filter
        if regime_row.get('vol_regime', 0) == 1:  
            return probability > 0.65  

        # Use regime detector
        regime_detector = RegimeDetector()
        if not regime_detector.allow_trade(regime_row):
            return False
            
        return True
    
    def calculate_stop_loss(self, entry_price: float, atr: float) -> float:
        """Calculate stop loss level"""
        return entry_price - (self.config.stop_atr_multiplier * atr)
    
    def calculate_take_profit(self, entry_price: float, atr: float) -> float:
        """Calculate take profit level"""
        return entry_price + (self.config.tp_atr_multiplier * atr)
    
    def calculate_trailing_stop(self, entry_price: float, highest_price: float, atr: float) -> float:
        """Calculate trailing stop level"""
        return highest_price - (self.config.trailing_atr_multiplier * atr)
    
    def should_exit_position(self,
                           entry_price: float,
                           current_price: float,
                           highest_price: float,
                           lowest_price: float,
                           atr: float,
                           days_held: int) -> Tuple[bool, str]:
        """Determine if position should be exited"""
        
        # Stop loss
        stop_level = self.calculate_stop_loss(entry_price, atr)
        if lowest_price <= stop_level:
            return True, "stop_loss"
        
        # Take profit
        tp_level = self.calculate_take_profit(entry_price, atr)
        if highest_price >= tp_level:
            return True, "take_profit"
        
         # Profit protection after 50% gain
        if highest_price > entry_price * 1.5:  
            protective_stop = highest_price * 0.9  
            if current_price <= protective_stop:
                return True, "profit_protection"
        
        # Momentum-based exit
        recent_return = (current_price - highest_price) / highest_price
        if recent_return < -0.15 and days_held > 3:  
            return True, "momentum_exit"
    
        # Trailing stop 
        if highest_price > entry_price * 1.01:  
            trailing_level = self.calculate_trailing_stop(entry_price, highest_price, atr)
            if lowest_price <= trailing_level:
                return True, "trailing_stop"
        
        # Time-based exit
        if days_held >= self.config.max_hold_days:
            return True, "time_exit"
            
        return False, "hold"

# =========================
# Cost model
# =========================
class CostModel:
    """Comprehensive transaction cost model"""
    
    def __init__(self, config: TradingConfig):
        self.config = config
        # Indian market costs 
        self.brokerage_rate = 0.0002      
        self.stt_rate = 0.001             
        self.exchange_charges = 0.0000325 
        self.sebi_charges = 10 / 1e7      
        self.gst_rate = 0.18              
        self.stamp_duty = 0.00015        
        
    def calculate_transaction_cost(self, side: str, notional_value: float) -> float:
        """Calculate total transaction cost"""
        
        # Brokerage
        brokerage = notional_value * self.brokerage_rate
        
        # Exchange charges
        exchange = notional_value * self.exchange_charges
        
        # SEBI charges
        sebi = notional_value * self.sebi_charges
        
        # GST on brokerage and exchange charges
        gst = (brokerage + exchange) * self.gst_rate
        
        # STT 
        stt = notional_value * self.stt_rate if side.lower() == 'sell' else 0
        
        # Stamp duty 
        stamp = notional_value * self.stamp_duty if side.lower() == 'buy' else 0
        
        total_cost = brokerage + exchange + sebi + gst + stt + stamp
        
        return total_cost
    
    def calculate_market_impact(self, trade_size: float, avg_volume: float, volatility: float) -> float:
        """Estimate market impact cost"""
        
        if avg_volume <= 0:
            return 0.01 
            
        
        participation = trade_size / avg_volume
        
      
        impact = self.config.impact_coefficient * math.sqrt(participation) * volatility
        
        return min(impact, 0.05) 

# =========================
# Backtester
# =========================
class Backtester:
    """Comprehensive backtesting engine with walk-forward analysis"""
    
    def __init__(self, 
                 price_data: pd.DataFrame,
                 feature_data: pd.DataFrame, 
                 regime_data: pd.DataFrame,
                 config: TradingConfig):
        
        self.price_data = price_data.sort_index()
        self.feature_data = feature_data.sort_index()
        self.regime_data = regime_data.sort_index()
        self.config = config
        self.cost_model = CostModel(config)
        self.risk_manager = RiskManager(config)
        
    def run_backtest(self, 
                    model: MLPipeline,
                    threshold_optimizer: DynamicThresholdOptimizer,
                    initial_capital: float = 100000) -> Dict[str, Any]:
        """Run comprehensive backtest"""
        
        logger.info("Starting backtest...")
        
      
        common_index = (self.price_data.index
                       .intersection(self.feature_data.index)
                       .intersection(self.regime_data.index))
        
        prices = self.price_data.loc[common_index]
        features = self.feature_data.loc[common_index]
        regimes = self.regime_data.loc[common_index]
        
       
        X = features.drop(['target_return', 'target_direction'], axis=1, errors='ignore')
        y = features['target_direction'].astype(int)
        returns = features['target_return']
        
      
        logger.info("Training model...")
        model_metrics = model.fit(X, y, n_splits=5)
        
       
        probabilities = pd.Series(model.predict_proba(X), index=X.index)
        
      
        logger.info("Optimizing thresholds...")
        threshold_optimizer.regime_thresholds = threshold_optimizer.optimize_by_regime(
            probabilities, y, regimes, returns
        )
        
       
        results = self._simulate_trading(
            prices, features, regimes, probabilities, 
            threshold_optimizer, initial_capital
        )
        
        
        results['model_metrics'] = model_metrics
        results['feature_importance'] = model.get_feature_importance()
        
        return results
    
    def _simulate_trading(self,
                         prices: pd.DataFrame,
                         features: pd.DataFrame, 
                         regimes: pd.DataFrame,
                         probabilities: pd.Series,
                         threshold_optimizer: DynamicThresholdOptimizer,
                         initial_capital: float) -> Dict[str, Any]:
        """Simulate trading strategy"""
        
        
        capital = initial_capital
        position_shares = 0.0
        position_entry_price = 0.0
        position_highest_price = 0.0
        position_days_held = 0
        
       
        nav_history = []
        position_history = []
        trade_history = []
        
        
        avg_volume = prices['volume'].rolling(20).mean().fillna(method='bfill')
        
        for i in range(1, len(prices) - 1):
            current_date = prices.index[i]
            current_bar = prices.iloc[i]
            next_bar = prices.iloc[i + 1]
            
            current_regime = regimes.loc[current_date]
            current_prob = probabilities.loc[current_date]
            
            
            current_vol = features.loc[current_date, 'vol_20'] if 'vol_20' in features.columns else 0.02
            current_atr = features.loc[current_date, 'atr_14'] if 'atr_14' in features.columns else current_bar['high'] - current_bar['low']
            
            
            nav = capital + position_shares * current_bar['close']
            nav_history.append(nav)
            position_history.append(position_shares)
            
            
            peak_nav = max(nav_history) if nav_history else initial_capital
            current_drawdown = (nav - peak_nav) / peak_nav
            
            
            if position_shares > 0:
                position_days_held += 1
                position_highest_price = max(position_highest_price, current_bar['high'])
                
               
                should_exit, exit_reason = self.risk_manager.should_exit_position(
                    position_entry_price,
                    current_bar['close'],
                    position_highest_price,
                    current_bar['low'],
                    current_atr,
                    position_days_held
                )
                
                if should_exit:
                    exit_price = next_bar['open']
                    
                    
                    impact_cost = self.cost_model.calculate_market_impact(
                        position_shares * exit_price,
                        avg_volume.loc[current_date] * current_bar['close'],
                        current_vol
                    )
                    
                    
                    actual_exit_price = exit_price * (1 - impact_cost)
                    notional = position_shares * actual_exit_price
                    transaction_cost = self.cost_model.calculate_transaction_cost('sell', notional)
                    
                    
                    capital += notional - transaction_cost
                    
                    pnl = (actual_exit_price - position_entry_price) * position_shares - transaction_cost
                    trade_history.append({
                        'exit_date': next_bar.name,
                        'exit_price': actual_exit_price,
                        'shares': position_shares,
                        'pnl': pnl,
                        'exit_reason': exit_reason,
                        'days_held': position_days_held,
                        'return_pct': pnl / (position_entry_price * position_shares)
                    })
                    
                    
                    position_shares = 0.0
                    position_entry_price = 0.0
                    position_highest_price = 0.0
                    position_days_held = 0
                    
                    continue
            
            
            if position_shares == 0:
                threshold = threshold_optimizer.get_threshold(current_regime)
                
                if (current_prob > threshold and 
                    self.risk_manager.should_enter_position(current_prob, current_regime, current_drawdown)):
                    
                    
                    entry_price = next_bar['open']
                    position_size = self.risk_manager.calculate_position_size(
                        capital, entry_price, current_prob, current_vol, current_atr
                    )
                    
                    if position_size > 0:
                        
                        impact_cost = self.cost_model.calculate_market_impact(
                            position_size * entry_price,
                            avg_volume.loc[current_date] * current_bar['close'],
                            current_vol
                        )
                        
                        actual_entry_price = entry_price * (1 + impact_cost)
                        notional = position_size * actual_entry_price
                        transaction_cost = self.cost_model.calculate_transaction_cost('buy', notional)
                        
                       
                        total_cost = notional + transaction_cost
                        if total_cost <= capital:
                            
                            capital -= total_cost
                            position_shares = position_size
                            position_entry_price = actual_entry_price
                            position_highest_price = actual_entry_price
                            position_days_held = 0
                            
                            
                            trade_history.append({
                                'entry_date': next_bar.name,
                                'entry_price': actual_entry_price,
                                'shares': position_size,
                                'probability': current_prob,
                                'regime': threshold_optimizer._create_regime_code(current_regime),
                                'transaction_cost': transaction_cost
                            })
        
     
        nav_series = pd.Series(nav_history, index=prices.index[1:-1])
        position_series = pd.Series(position_history, index=prices.index[1:-1])
        returns_series = nav_series.pct_change().fillna(0)
        
        # Performance metrics
        performance_stats = self._calculate_performance_stats(nav_series, returns_series, trade_history)
        
        return {
            'nav_series': nav_series,
            'position_series': position_series,
            'returns_series': returns_series,
            'trade_history': trade_history,
            'performance_stats': performance_stats
        }
    
    def _calculate_performance_stats(self, 
                                   nav_series: pd.Series,
                                   returns_series: pd.Series, 
                                   trade_history: List[Dict]) -> Dict[str, float]:
        """Calculate comprehensive performance statistics"""
        
        if len(nav_series) == 0:
            return {}
        
        initial_nav = nav_series.iloc[0]
        final_nav = nav_series.iloc[-1]
        
        # Basic metrics
        total_return = (final_nav / initial_nav) - 1
        cagr_val = cagr(returns_series)
        sharpe_val = sharpe_ratio(returns_series)
        sortino_val = sortino_ratio(returns_series)
        
        # Risk metrics
        max_dd = max_drawdown((1 + returns_series).cumprod())
        calmar_val = calmar_ratio(returns_series)
        omega_val = omega_ratio(returns_series)
        
        # Trade statistics
        completed_trades = [t for t in trade_history if 'pnl' in t]
        
        if completed_trades:
            winning_trades = [t for t in completed_trades if t['pnl'] > 0]
            losing_trades = [t for t in completed_trades if t['pnl'] <= 0]
            
            win_rate = len(winning_trades) / len(completed_trades)
            avg_win = np.mean([t['pnl'] for t in winning_trades]) if winning_trades else 0
            avg_loss = np.mean([abs(t['pnl']) for t in losing_trades]) if losing_trades else 0
            profit_factor = abs(avg_win / avg_loss) if avg_loss > 0 else float('inf')
            
            avg_holding_period = np.mean([t['days_held'] for t in completed_trades])
        else:
            win_rate = 0
            avg_win = 0
            avg_loss = 0
            profit_factor = 0
            avg_holding_period = 0
        
        return {
            'total_return': total_return,
            'cagr': cagr_val,
            'sharpe_ratio': sharpe_val,
            'sortino_ratio': sortino_val,
            'max_drawdown': max_dd,
            'calmar_ratio': calmar_val,
            'omega_ratio': omega_val,
            'win_rate': win_rate,
            'profit_factor': profit_factor,
            'num_trades': len(completed_trades),
            'avg_holding_period': avg_holding_period,
            'avg_win': avg_win,
            'avg_loss': avg_loss
        }

# =========================
# Performance Visualization
# =========================
class PerformanceVisualizer:
    """Comprehensive portfolio performance visualization with Plotly"""
    
    def __init__(self):
        if not PLOTLY_AVAILABLE:
            logger.warning("Plotly not available. Install with: pip install plotly")
    
    def create_comprehensive_dashboard(self, results: Dict[str, Any], symbol: str, 
                                    benchmark_data: pd.DataFrame = None) -> Dict[str, go.Figure]:
        """Create complete trading dashboard"""
        
        if not PLOTLY_AVAILABLE:
            logger.warning("Plotly not available - skipping visualizations")
            return {}
        
        nav_series = results['nav_series']
        returns_series = results['returns_series']
        trade_history = results['trade_history']
        
        figures = {}
        
        # 1. MAIN PERFORMANCE CHART
        figures['performance'] = self.plot_portfolio_performance(
            nav_series, benchmark_data, trade_history, symbol
        )
        
        # 2. DRAWDOWN ANALYSIS
        figures['drawdown'] = self.plot_drawdown_analysis(nav_series, returns_series)
        
        # 3. TRADE ANALYSIS
        figures['trades'] = self.plot_trade_analysis(trade_history)
        
        # 4. MONTHLY RETURNS HEATMAP
        figures['monthly_returns'] = self.plot_monthly_returns_heatmap(returns_series)
        
        # 5. ROLLING METRICS
        figures['rolling_metrics'] = self.plot_rolling_metrics(returns_series)
        
        return figures
    
    def plot_portfolio_performance(self, nav_series: pd.Series, benchmark_data: pd.DataFrame,
                                 trade_history: List[Dict], symbol: str) -> go.Figure:
        """ Portfolio vs benchmark performance"""
        
        fig = make_subplots(
            rows=3, cols=1,
            shared_xaxes=True,
            vertical_spacing=0.05,
            subplot_titles=[
                f"Portfolio vs Benchmark Performance - {symbol}",
                "Position Sizes Over Time", 
                "Trade Signals"
            ],
            row_heights=[0.6, 0.2, 0.2]
        )
        
        # Portfolio NAV
        fig.add_trace(
            go.Scatter(
                x=nav_series.index,
                y=nav_series.values,
                mode='lines',
                name='Portfolio NAV',
                line=dict(color='#1f77b4', width=2),
                hovertemplate='<b>Portfolio</b><br>Date: %{x}<br>NAV: Rs %{y:,.0f}<extra></extra>'
            ),
            row=1, col=1
        )
        
        # Benchmark comparison
        if benchmark_data is not None:
            benchmark_aligned = benchmark_data['close'].reindex(nav_series.index, method='ffill')
            benchmark_normalized = (benchmark_aligned / benchmark_aligned.iloc[0]) * nav_series.iloc[0]
            
            fig.add_trace(
                go.Scatter(
                    x=benchmark_normalized.index,
                    y=benchmark_normalized.values,
                    mode='lines',
                    name='Nifty 50',
                    line=dict(color='#ff7f0e', width=2, dash='dash'),
                    hovertemplate='<b>Benchmark</b><br>Date: %{x}<br>Value: Rs %{y:,.0f}<extra></extra>'
                ),
                row=1, col=1
            )
        
        # Position sizes
        entry_trades = [t for t in trade_history if 'entry_date' in t]
        if entry_trades:
            entry_dates = [t['entry_date'] for t in entry_trades]
            position_sizes = [t['shares'] for t in entry_trades]
            
            fig.add_trace(
                go.Bar(
                    x=entry_dates,
                    y=position_sizes,
                    name='Position Size',
                    marker_color='lightblue',
                    hovertemplate='<b>Position</b><br>Date: %{x}<br>Shares: %{y}<extra></extra>'
                ),
                row=2, col=1
            )
        
        # Trade signals
        entry_trades = [t for t in trade_history if 'entry_date' in t]
        exit_trades = [t for t in trade_history if 'exit_date' in t]
        
        if entry_trades:
            fig.add_trace(
                go.Scatter(
                    x=[t['entry_date'] for t in entry_trades],
                    y=[1] * len(entry_trades),
                    mode='markers',
                    name='Buy Signals',
                    marker=dict(color='green', size=10, symbol='triangle-up'),
                    hovertemplate='<b>BUY</b><br>Date: %{x}<br>Price: Rs %{text}<extra></extra>',
                    text=[f"{t['entry_price']:.2f}" for t in entry_trades]
                ),
                row=3, col=1
            )
        
        if exit_trades:
            fig.add_trace(
                go.Scatter(
                    x=[t['exit_date'] for t in exit_trades],
                    y=[-1] * len(exit_trades),
                    mode='markers',
                    name='Sell Signals',
                    marker=dict(color='red', size=10, symbol='triangle-down'),
                    hovertemplate='<b>SELL</b><br>Date: %{x}<br>Price: Rs %{text}<br>Reason: %{customdata}<extra></extra>',
                    text=[f"{t['exit_price']:.2f}" for t in exit_trades],
                    customdata=[t.get('exit_reason', 'N/A') for t in exit_trades]
                ),
                row=3, col=1
            )
        
        fig.update_layout(
            height=800,
            title=f"AI Trading Bot Performance Dashboard - {symbol}",
            hovermode='x unified',
            template='plotly_white'
        )
        
        return fig
    
    def plot_drawdown_analysis(self, nav_series: pd.Series, returns_series: pd.Series) -> go.Figure:
        """Detailed drawdown analysis"""
        
        # Calculate drawdowns
        cumulative_max = nav_series.cummax()
        drawdowns = (nav_series - cumulative_max) / cumulative_max * 100
        
        # Rolling volatility
        rolling_vol = returns_series.rolling(30).std() * np.sqrt(252) * 100
        
        fig = make_subplots(
            rows=2, cols=1,
            shared_xaxes=True,
            subplot_titles=["Drawdown Analysis", "Rolling 30-Day Volatility"],
            vertical_spacing=0.1
        )
        
        # Drawdowns
        fig.add_trace(
            go.Scatter(
                x=drawdowns.index,
                y=drawdowns.values,
                mode='lines',
                fill='tozeroy',
                name='Drawdown %',
                line=dict(color='red'),
                fillcolor='rgba(255, 0, 0, 0.3)',
                hovertemplate='<b>Drawdown</b><br>Date: %{x}<br>Drawdown: %{y:.2f}%<extra></extra>'
            ),
            row=1, col=1
        )
        
        # Rolling volatility
        fig.add_trace(
            go.Scatter(
                x=rolling_vol.index,
                y=rolling_vol.values,
                mode='lines',
                name='Annualized Vol %',
                line=dict(color='orange'),
                hovertemplate='<b>Volatility</b><br>Date: %{x}<br>Vol: %{y:.2f}%<extra></extra>'
            ),
            row=2, col=1
        )
        
        fig.update_layout(
            height=500,
            title="Risk Analysis Dashboard",
            template='plotly_white'
        )
        
        return fig
    
    def plot_trade_analysis(self, trade_history: List[Dict]) -> go.Figure:
        """Comprehensive trade analysis"""
        
        completed_trades = [t for t in trade_history if 'pnl' in t]
        
        if not completed_trades:
            fig = go.Figure()
            fig.add_annotation(text="No completed trades to analyze", 
                            xref="paper", yref="paper", x=0.5, y=0.5)
            return fig
        
        
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=[
                "P&L Distribution", 
                "Trade Returns Over Time",
                "Holding Period Analysis",
                "Exit Reason Breakdown"
            ],
            specs=[[{"type": "xy"}, {"type": "xy"}],
                [{"type": "xy"}, {"type": "domain"}]]  
        )
        
        # P&L distribution
        pnls = [t['pnl'] for t in completed_trades]
        fig.add_trace(
            go.Histogram(
                x=pnls,
                name='P&L Distribution',
                nbinsx=20,
                marker_color='lightblue'
            ),
            row=1, col=1
        )
        
        # Returns over time
        trade_dates = [t['exit_date'] for t in completed_trades]
        trade_returns = [t.get('return_pct', 0) * 100 for t in completed_trades]
        
        colors = ['green' if r > 0 else 'red' for r in trade_returns]
        
        fig.add_trace(
            go.Scatter(
                x=trade_dates,
                y=trade_returns,
                mode='markers+lines',
                name='Trade Returns %',
                marker=dict(color=colors, size=8),
                line=dict(color='gray', width=1)
            ),
            row=1, col=2
        )
        
        # Holding period
        holding_periods = [t['days_held'] for t in completed_trades]
        fig.add_trace(
            go.Histogram(
                x=holding_periods,
                name='Holding Period (Days)',
                nbinsx=15,
                marker_color='lightgreen'
            ),
            row=2, col=1
        )
        
        # Exit reasons 
        exit_reasons = [t.get('exit_reason', 'unknown') for t in completed_trades]
        exit_counts = pd.Series(exit_reasons).value_counts()
        
        fig.add_trace(
            go.Pie(
                labels=exit_counts.index,
                values=exit_counts.values,
                name='Exit Reasons'
            ),
            row=2, col=2
        )
        
        fig.update_layout(
            height=600,
            title="Trade Analysis Dashboard",
            template='plotly_white'
        )
        
        return fig

    
    def plot_monthly_returns_heatmap(self, returns_series: pd.Series) -> go.Figure:
        """Monthly returns heatmap"""
        
        # Monthly returns
        monthly_returns = returns_series.resample('M').apply(lambda x: (1 + x).prod() - 1)
        
        # Pivot table
        monthly_data = []
        for date, ret in monthly_returns.items():
            monthly_data.append({
                'Year': date.year,
                'Month': date.strftime('%b'),
                'Return': ret * 100
            })
        
        df_monthly = pd.DataFrame(monthly_data)
        pivot_table = df_monthly.pivot(index='Year', columns='Month', values='Return')
        
        # Reorder months
        month_order = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 
                      'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
        pivot_table = pivot_table.reindex(columns=month_order)
        
        fig = go.Figure(data=go.Heatmap(
            z=pivot_table.values,
            x=pivot_table.columns,
            y=pivot_table.index,
            colorscale='RdYlGn',
            zmid=0,
            text=np.round(pivot_table.values, 2),
            texttemplate='%{text}%',
            textfont={'size': 10},
            hovertemplate='Year: %{y}<br>Month: %{x}<br>Return: %{z:.2f}%<extra></extra>'
        ))
        
        fig.update_layout(
            title="Monthly Returns Heatmap (%)",
            height=400,
            template='plotly_white'
        )
        
        return fig
    
    def plot_rolling_metrics(self, returns_series: pd.Series) -> go.Figure:
        """Rolling performance metrics"""
        
        # Calculate rolling metrics
        rolling_sharpe = returns_series.rolling(252).apply(
            lambda x: (x.mean() / x.std()) * np.sqrt(252) if x.std() > 0 else 0
        )
        
        rolling_sortino = returns_series.rolling(252).apply(
            lambda x: (x.mean() / x[x < 0].std()) * np.sqrt(252) if len(x[x < 0]) > 0 and x[x < 0].std() > 0 else 0
        )
        
        fig = make_subplots(
            rows=2, cols=1,
            shared_xaxes=True,
            subplot_titles=["Rolling Sharpe Ratio (252 days)", "Rolling Sortino Ratio (252 days)"]
        )
        
        # Rolling Sharpe
        fig.add_trace(
            go.Scatter(
                x=rolling_sharpe.index,
                y=rolling_sharpe.values,
                mode='lines',
                name='Rolling Sharpe',
                line=dict(color='blue')
            ),
            row=1, col=1
        )
        
        
        fig.add_hline(y=1.0, line_dash="dash", line_color="gray", row=1, col=1)
        
        # Rolling Sortino
        fig.add_trace(
            go.Scatter(
                x=rolling_sortino.index,
                y=rolling_sortino.values,
                mode='lines',
                name='Rolling Sortino',
                line=dict(color='purple')
            ),
            row=2, col=1
        )
        
        fig.update_layout(
            height=500,
            title="Rolling Risk-Adjusted Performance Metrics",
            template='plotly_white'
        )
        
        return fig

# =========================
# Data manager
# =========================
class DataManager:
    """Data management with multiple data sources"""
    
    INDIAN_BLUE_CHIPS = {
        'RELIANCE': 'RELIANCE.NS',
        'TCS': 'TCS.NS', 
        'HDFCBANK': 'HDFCBANK.NS',
        'INFY': 'INFY.NS',
        'HINDUNILVR': 'HINDUNILVR.NS',
        'ICICIBANK': 'ICICIBANK.NS',
        'KOTAKBANK': 'KOTAKBANK.NS',
        'BHARTIARTL': 'BHARTIARTL.NS',
        'ITC': 'ITC.NS',
        'ASIANPAINT': 'ASIANPAINT.NS',
        'MARUTI': 'MARUTI.NS',
        'AXISBANK': 'AXISBANK.NS',
        'LT': 'LT.NS',
        'SUNPHARMA': 'SUNPHARMA.NS',
        'TITAN': 'TITAN.NS',
        'ULTRACEMCO': 'ULTRACEMCO.NS',
        'NESTLEIND': 'NESTLEIND.NS',
        'WIPRO': 'WIPRO.NS',
        'JSWSTEEL': 'JSWSTEEL.NS',
        'TATAMOTORS': 'TATAMOTORS.NS',
        'HCLTECH': 'HCLTECH.NS',
        'POWERGRID': 'POWERGRID.NS',
        'NTPC': 'NTPC.NS',
        'ONGC': 'ONGC.NS',
        'COALINDIA': 'COALINDIA.NS'
    }
    
    def __init__(self):
        if not YF_AVAILABLE:
            raise RuntimeError("yfinance not available. Please install: pip install yfinance")
    
    def download_data(self, 
                     symbol: str, 
                     period: str = "10y", 
                     interval: str = "1d") -> pd.DataFrame:
        """Download price data with error handling"""
        
        # Get yfinance symbol
        yf_symbol = self.INDIAN_BLUE_CHIPS.get(symbol, 
                                              symbol if symbol.endswith('.NS') else f"{symbol}.NS")
        
        logger.info(f"Downloading data for {yf_symbol}...")
        
        try:
            ticker = yf.Ticker(yf_symbol)
            data = ticker.history(period=period, interval=interval)
            
            if data.empty:
                raise ValueError(f"No data returned for {yf_symbol}")
            
            # Clean and standardize data
            data = data.reset_index()
            data.columns = [col.lower().replace(' ', '_') for col in data.columns]
            
            # Handle date column
            date_col = 'date' if 'date' in data.columns else 'datetime'
            if date_col in data.columns:
                data = data.rename(columns={date_col: 'timestamp'})
            
            data = data.set_index('timestamp')
            
            # Validate required columns
            required_cols = ['open', 'high', 'low', 'close', 'volume']
            missing_cols = [col for col in required_cols if col not in data.columns]
            if missing_cols:
                raise ValueError(f"Missing required columns: {missing_cols}")
            
            # Clean data
            data = self._clean_price_data(data)
            
            logger.info(f"Downloaded {len(data)} bars for {yf_symbol}")
            return data
            
        except Exception as e:
            logger.error(f"Error downloading data for {yf_symbol}: {e}")
            raise
    
    def _clean_price_data(self, data: pd.DataFrame) -> pd.DataFrame:
        """Clean price data"""
        
        # Remove rows with missing OHLC data
        data = data.dropna(subset=['open', 'high', 'low', 'close'])
        
        # Remove rows where high < low (data errors)
        data = data[data['high'] >= data['low']]
        
        # Remove rows with zero volume (if volume exists)
        if 'volume' in data.columns:
            data = data[data['volume'] > 0]
        
        # Remove extreme outliers (price changes > 50% in one day)
        returns = data['close'].pct_change()
        data = data[abs(returns) < 0.5]
        
        # Ensure proper data types
        numeric_cols = ['open', 'high', 'low', 'close', 'volume']
        for col in numeric_cols:
            if col in data.columns:
                data[col] = pd.to_numeric(data[col], errors='coerce')
        
        return data
    def download_market_index(self, period: str = "2y") -> pd.DataFrame:
        """Download Nifty 50 index data for market correlation"""
        try:
            ticker = yf.Ticker("^NSEI")  # Nifty 50 index
            data = ticker.history(period=period, interval="1d")
            
            if data.empty:
                logger.warning("No Nifty data available, market correlation features will use fallback")
                return None
                
            # Clean and standardize
            data = data.reset_index()
            data.columns = [col.lower().replace(' ', '_') for col in data.columns]
            data = data.set_index('date' if 'date' in data.columns else data.columns[0])
            
            return self._clean_price_data(data)
            
        except Exception as e:
            logger.warning(f"Failed to download market index: {e}")
            return None

# =========================
# AI Trading bot
# =========================
class AITradingBot:
    """Institution-level AI trading bot with end-to-end workflow"""
    
    def __init__(self, config: Optional[TradingConfig] = None):
        self.config = config or TradingConfig()
        self.data_manager = DataManager()
        self.feature_builder = FeatureBuilder()
        self.model = MLPipeline(self.config)
        self.threshold_optimizer = DynamicThresholdOptimizer(self.config)
        self.visualizer = PerformanceVisualizer()
        
    def run_analysis(self, 
            symbol: str = 'TATAMOTORS',
            period: str = '3y',
            initial_capital: float = 100000,
            show_plots: bool = True,
            save_html: bool = True) -> Dict[str, Any]:
        """Run complete trading analysis with timestamped folder organization"""
        
        logger.info(f"Starting analysis for {symbol}")
        
        # STEP 1: Create timestamped folder
        from datetime import datetime
        import os
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        reports_folder = f"reports/{symbol}_{timestamp}"
        os.makedirs(reports_folder, exist_ok=True)
        
        try:
            # Your existing data processing code (unchanged)
            price_data = self.data_manager.download_data(symbol, period)
            market_data = self.data_manager.download_market_index(period)
            feature_data = self.feature_builder.build_features(price_data, market_data=market_data)
            regime_data = self.feature_builder.regime_detector.detect(price_data)
            
            backtester = Backtester(price_data, feature_data, regime_data, self.config)
            results = backtester.run_backtest(self.model, self.threshold_optimizer, initial_capital)
            
            if show_plots and PLOTLY_AVAILABLE:
                logger.info("Creating comprehensive visualizations...")
                figures = self.visualizer.create_comprehensive_dashboard(
                    results, symbol, market_data
                )
                
                # STEP 2: Save all HTML files to timestamped folder
                if save_html:
                    for name, fig in figures.items():
                        if fig:
                            filepath = os.path.join(reports_folder, f"{name}_dashboard.html")
                            fig.write_html(filepath)
                            logger.info(f"Saved: {filepath}")
                    
                    # STEP 3: Save pickle file to same folder
                    import pickle
                    pickle_path = os.path.join(reports_folder, 'results.pkl')
                    with open(pickle_path, 'wb') as f:
                        pickle.dump(results, f)
                    logger.info(f"Saved results: {pickle_path}")
                    
                    # STEP 4: Create master index and open browser
                    self._create_master_index(symbol, reports_folder)
                    
                    # STEP 5: Optional cleanup of old reports
                    self._cleanup_old_reports(symbol, keep_last=5)
                
                results['figures'] = figures
                
            elif show_plots and not PLOTLY_AVAILABLE:
                logger.warning("Plotly not available. Install with: pip install plotly")
            
            self._print_analysis_report(symbol, results)
            return results
            
        except Exception as e:
            logger.error(f"Analysis failed: {e}")
            raise


    def _print_analysis_report(self, symbol: str, results: Dict[str, Any]):
        """Analysis report with signal quality focus"""
        
        stats = results['performance_stats']
        model_metrics = results.get('model_metrics', {})
        
        print("\n" + "=" * 90)
        print(f" AI TRADING BOT ANALYSIS - {symbol}")
        print("=" * 90)
        
        auc = model_metrics.get('auc', 0)
        accuracy = model_metrics.get('accuracy', 0)
        
        print(f"\n SIGNAL QUALITY ASSESSMENT:")
        print(f"  Model AUC:        {auc:.3f}")
        print(f"  Model Accuracy:   {accuracy:.3f}")
        
        if auc > 0.55:
            print(f"   SIGNAL STRENGTH: STRONG - Good predictive power")
        elif auc > 0.52:
            print(f"   SIGNAL STRENGTH: MODERATE - Some predictive power") 
        else:
            print(f"   SIGNAL STRENGTH: WEAK - Poor predictive signals")
            print(f"   RECOMMENDATION: Need better feature engineering")
        
        
        sharpe = stats.get('sharpe_ratio', 0)
        num_trades = stats.get('num_trades', 0)
        win_rate = stats.get('win_rate', 0)
        
        print(f"\n STRATEGY PERFORMANCE:")
        print(f"  Total Return:     {stats.get('total_return', 0):.2%}")
        print(f"  Sharpe Ratio:     {sharpe:.3f}")
        print(f"  Win Rate:         {win_rate:.1%}")
        print(f"  Number of Trades: {num_trades}")
        print(f"  Max Drawdown:     {stats.get('max_drawdown', 0):.2%}")
        
        
        print(f"\n OVERALL ASSESSMENT:")
        if auc > 0.55 and sharpe > 1.0:
            print(f" EXCELLENT: Strong signals + great returns")
        elif auc > 0.52 and sharpe > 0.5:
            print(f" GOOD: Decent signals + positive returns")
        elif auc > 0.52:
            print(f"PROMISING: Good signals but execution needs work")
        else:
            print(f"  NEEDS MAJOR IMPROVEMENT:")
            print(f"     - Feature engineering is insufficient")
            print(f"     - Model cannot distinguish profitable patterns")
            print(f"     - Consider alternative data sources")
        
        print("\n" + "=" * 90)

    def _create_dashboard_index(self, symbol: str):
        """Create an index HTML file linking to all dashboards"""
        import webbrowser
        import os
        
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>{symbol} AI Trading Bot Dashboard</title>
            <style>
                body {{ 
                    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; 
                    margin: 40px; 
                    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                    color: white;
                }}
                .container {{
                    background: rgba(255,255,255,0.1);
                    padding: 30px;
                    border-radius: 15px;
                    backdrop-filter: blur(10px);
                }}
                h1 {{ color: #fff; text-align: center; margin-bottom: 30px; }}
                h2 {{ color: #f0f0f0; }}
                .dashboard-link {{ 
                    display: block; 
                    padding: 20px; 
                    margin: 15px 0; 
                    background: rgba(255,255,255,0.2); 
                    text-decoration: none; 
                    border-radius: 10px;
                    color: white;
                    font-weight: bold;
                    font-size: 16px;
                    transition: all 0.3s ease;
                }}
                .dashboard-link:hover {{ 
                    background: rgba(255,255,255,0.3); 
                    transform: translateY(-2px);
                    box-shadow: 0 5px 15px rgba(0,0,0,0.2);
                }}
                .emoji {{ font-size: 24px; margin-right: 10px; }}
            </style>
        </head>
        <body>
            <div class="container">
                <h1>&#129302; {symbol} AI Trading Bot Analysis</h1>
                <h2>&#128200; Interactive Trading Dashboards</h2>
                
                <a href="{symbol}_performance_dashboard.html" class="dashboard-link">
                    <span class="emoji">&#128200;</span> Portfolio Performance 
                </a>
                <a href="{symbol}_drawdown_dashboard.html" class="dashboard-link">
                    <span class="emoji">&#128201;</span> Risk Analysis 
                </a>
                <a href="{symbol}_trades_dashboard.html" class="dashboard-link">
                    <span class="emoji">&#128176;</span> Trade Analysis & P&L Distribution
                </a>
                <a href="{symbol}_monthly_returns_dashboard.html" class="dashboard-link">
                    <span class="emoji">&#128197;</span> Monthly Returns Heatmap
                </a>
                <a href="{symbol}_rolling_metrics_dashboard.html" class="dashboard-link">
                    <span class="emoji">&#128200;</span> Rolling Performance Metrics
                </a>
                
                <hr style="margin: 30px 0; border: 1px solid rgba(255,255,255,0.3);">
                <p style="text-align: center; opacity: 0.8;">
                    &#127919; Analysis complete! Click on any dashboard above to explore detailed insights.
                </p>
            </div>
        </body>
        </html>
        """
        
        index_filename = f"{symbol}_dashboard_index.html"
        with open(index_filename, 'w', encoding='utf-8') as f:  # FIXED: Added encoding='utf-8'
            f.write(html_content)
        
        
        index_path = os.path.abspath(index_filename)
        webbrowser.open(f'file://{index_path}')
        logger.info(f"Dashboard index opened: {index_filename}")

    def _create_master_index(self, symbol: str, latest_folder: str):
        """Create a master index HTML pointing to latest reports"""
        import webbrowser
        
        html_files = [f for f in os.listdir(latest_folder) if f.endswith('.html')]
        
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>{symbol} AI Trading Bot - Latest Reports</title>
            <style>
                body {{ 
                    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; 
                    margin: 40px; 
                    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                    color: white;
                    min-height: 100vh;
                }}
                .container {{
                    background: rgba(255,255,255,0.1);
                    padding: 30px;
                    border-radius: 15px;
                    backdrop-filter: blur(10px);
                    max-width: 800px;
                    margin: 0 auto;
                }}
                h1 {{ color: #fff; text-align: center; margin-bottom: 30px; }}
                h2 {{ color: #f0f0f0; }}
                .report-link {{ 
                    display: block; 
                    padding: 15px; 
                    margin: 10px 0; 
                    background: rgba(255,255,255,0.2); 
                    text-decoration: none; 
                    border-radius: 8px;
                    color: white;
                    font-weight: bold;
                    transition: all 0.3s ease;
                }}
                .report-link:hover {{ 
                    background: rgba(255,255,255,0.3); 
                    transform: translateY(-2px);
                    box-shadow: 0 5px 15px rgba(0,0,0,0.2);
                }}
                .timestamp {{ 
                    opacity: 0.8; 
                    font-size: 14px; 
                    text-align: center; 
                    margin-top: 20px; 
                }}
            </style>
        </head>
        <body>
            <div class="container">
                <h1> AI POWERED TRADING BOT </h1>
                <h2> Analysis of {symbol}</h2>
                
                <div class="reports">
        """
        
        
        for html_file in sorted(html_files):
            report_name = html_file.replace('_dashboard.html', '').replace('_', ' ').title()
            relative_path = f"{os.path.basename(latest_folder)}/{html_file}"
            html_content += f'<a href="{relative_path}" class="report-link"> {report_name}</a>\n'
        
        html_content += f"""
                </div>
                
                <div class="timestamp">
                    Generated by Aaditya V: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
                </div>
            </div>
        </body>
        </html>
        """
        
        
        index_filename = f"reports/{symbol}_latest_index.html"
        with open(index_filename, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        
        index_path = os.path.abspath(index_filename)
        webbrowser.open(f'file://{index_path}')
        logger.info(f"Dashboard index opened: {index_filename}")

    def _cleanup_old_reports(self, symbol: str, keep_last: int = 5):
        """Remove old report folders, keeping only the most recent ones"""
        import glob
        import shutil
        
        
        pattern = f"reports/{symbol}_*"
        folders = sorted(glob.glob(pattern), reverse=True)  
        
    
        old_folders = folders[keep_last:]
        for folder in old_folders:
            try:
                shutil.rmtree(folder)
                logger.info(f"Cleaned up old reports: {folder}")
            except Exception as e:
                logger.warning(f"Could not delete {folder}: {e}")
        
        if old_folders:
            logger.info(f"Kept {min(len(folders), keep_last)} most recent report folders")

# =========================
# Main execution
# =========================
def main():
    """Main execution"""
    
    config = TradingConfig(
        target_annual_vol=0.18,
        max_drawdown=0.12,
        min_confidence=0.58,
        kelly_fraction=0.6,
        stop_atr_multiplier=3.0,
        tp_atr_multiplier=6.0,
        max_hold_days=35
    )
    
    bot = AITradingBot(config)
    
   
    symbol = 'RELIANCE'
    
    try:
        logger.info(f"Running analysis for {symbol}...")
        results = bot.run_analysis(
            symbol=symbol,
            period='5y',
            initial_capital=500000,
            show_plots=True  
        )
        
       
            
    except Exception as e:
        logger.error(f"Analysis failed: {e}")

if __name__ == "__main__":
    main()

